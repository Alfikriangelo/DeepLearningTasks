{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9jJZy+DpzO0d+VmIPiEiM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alfikriangelo/DeepLearningTasks/blob/main/2ndWeekTask/SecondHand_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch**"
      ],
      "metadata": {
        "id": "Ob7ZODKTw7AZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JAHL16Y-segI"
      },
      "outputs": [],
      "source": [
        "#import library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. MEMUAT DATASET\n",
        "data = pd.read_csv('sample_data/secondhanddataset.csv')"
      ],
      "metadata": {
        "id": "maFZ7rv3wZvu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. PRA-PROSES DATA\n",
        "# Pisahkan fitur (X) dan target harga (y)\n",
        "X = data.drop(columns=['current price']).values\n",
        "y = data['current price'].values.reshape(-1, 1)  # Bentuk y harus (n_samples, 1)"
      ],
      "metadata": {
        "id": "CMC_NRXUwcl9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi data menjadi data latih (80%) dan data uji (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FOqbJzKSwdgP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisasi fitur agar memiliki distribusi yang lebih stabil\n",
        "scaler_X = StandardScaler()\n",
        "X_train = scaler_X.fit_transform(X_train)\n",
        "X_test = scaler_X.transform(X_test)"
      ],
      "metadata": {
        "id": "w-XprA3WwgAN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisasi target agar model lebih cepat konvergen\n",
        "scaler_y = StandardScaler()\n",
        "y_train = scaler_y.fit_transform(y_train)\n",
        "y_test = scaler_y.transform(y_test)"
      ],
      "metadata": {
        "id": "vQH_EsUrwgy3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi data ke Tensor PyTorch\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "D01X24TWwhFA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. MEMBUAT DATASET UNTUK MINI-BATCH TRAINING\n",
        "batch_size = 32  # Ukuran batch untuk setiap iterasi pelatihan\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "AH7uB8CcwkIs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. MEMBANGUN MODEL MLP\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)  # Lapisan pertama dengan 128 neuron\n",
        "        self.fc2 = nn.Linear(128, 64)  # Lapisan kedua dengan 64 neuron\n",
        "        self.fc3 = nn.Linear(64, 1)  # Lapisan output (tanpa aktivasi karena regresi)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))  # Aktivasi ReLU untuk lapisan pertama\n",
        "        x = torch.relu(self.fc2(x))  # Aktivasi ReLU untuk lapisan kedua\n",
        "        x = self.fc3(x)  # Output tanpa aktivasi\n",
        "        return x"
      ],
      "metadata": {
        "id": "6R9q2Igcwl_1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi model dengan jumlah fitur yang sesuai\n",
        "model = MLP(input_dim=X_train.shape[1])"
      ],
      "metadata": {
        "id": "VfuVw9_JwoaU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. MENDEFINISIKAN LOSS FUNCTION DAN OPTIMIZER\n",
        "criterion = nn.MSELoss()  # Fungsi loss menggunakan Mean Squared Error (MSE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)  # Optimizer Adam dengan learning rate kecil agar stabil"
      ],
      "metadata": {
        "id": "XGua8D6xwrLW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. LOOP PELATIHAN MODEL\n",
        "epochs = 100  # Jumlah iterasi pelatihan\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Mengaktifkan mode pelatihan\n",
        "    epoch_loss = 0  # Menyimpan akumulasi loss per epoch\n",
        "\n",
        "    for batch_X, batch_y in train_loader:  # Iterasi melalui batch dalam DataLoader\n",
        "        optimizer.zero_grad()  # Reset gradien sebelum backpropagation\n",
        "        outputs = model(batch_X)  # Prediksi dari model\n",
        "        loss = criterion(outputs, batch_y)  # Hitung loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update bobot model\n",
        "        epoch_loss += loss.item()  # Simpan total loss\n",
        "\n",
        "    # Tampilkan loss setiap 10 epoch\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss / len(train_loader):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8R6GvNQwsM-",
        "outputId": "bfd186e0-5962-40db-f501-20642379f4a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.0057\n",
            "Epoch [20/100], Loss: 0.0024\n",
            "Epoch [30/100], Loss: 0.0016\n",
            "Epoch [40/100], Loss: 0.0011\n",
            "Epoch [50/100], Loss: 0.0008\n",
            "Epoch [60/100], Loss: 0.0006\n",
            "Epoch [70/100], Loss: 0.0005\n",
            "Epoch [80/100], Loss: 0.0003\n",
            "Epoch [90/100], Loss: 0.0003\n",
            "Epoch [100/100], Loss: 0.0002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. EVALUASI MODEL\n",
        "model.eval()  # Mengaktifkan mode evaluasi\n",
        "with torch.no_grad():  # Tidak perlu menghitung gradien saat evaluasi\n",
        "    y_pred = model(X_test)  # Prediksi data uji\n",
        "    mse = criterion(y_pred, y_test)  # Hitung MSE\n",
        "    rmse = torch.sqrt(mse)  # Hitung RMSE\n",
        "\n",
        "    # Konversi hasil prediksi kembali ke skala asli\n",
        "    y_pred_original = scaler_y.inverse_transform(y_pred.numpy())\n",
        "    y_test_original = scaler_y.inverse_transform(y_test.numpy())\n",
        "\n",
        "    # Hitung R-squared dalam skala asli\n",
        "    y_mean = np.mean(y_test_original)\n",
        "    ss_total = np.sum((y_test_original - y_mean) ** 2)  # Total Variasi\n",
        "    ss_res = np.sum((y_test_original - y_pred_original) ** 2)  # Variasi yang tidak dapat dijelaskan\n",
        "    r_squared = 1 - (ss_res / ss_total)  # R-squared"
      ],
      "metadata": {
        "id": "hT6k-avQwwMM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k3qrfuGmx5QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. MENAMPILKAN HASIL EVALUASI\n",
        "print(f'MSE: {mse.item():.4f}')\n",
        "print(f'RMSE: {rmse.item():.4f}')\n",
        "print(f'R-squared: {r_squared:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRXN4UQFwyh_",
        "outputId": "687f8dae-d145-4211-8423-a32f162dda77"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.0035\n",
            "RMSE: 0.0590\n",
            "R-squared: 0.9968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluasi Model: MSE, RMSE, dan R-squared**\n",
        "\n",
        "Setelah melatih model, kita mengevaluasi performanya menggunakan tiga metrik utama:\n",
        "\n",
        "1. **Mean Squared Error (MSE)**\n",
        "2. **Root Mean Squared Error (RMSE)**\n",
        "3. **R-squared (\\( R^2 \\))**\n",
        "\n",
        "Hasil evaluasi yang diperoleh:"
      ],
      "metadata": {
        "id": "_bhiIGTH3tD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **1. Mean Squared Error (MSE)**\n",
        "MSE mengukur rata-rata kesalahan kuadrat antara nilai prediksi dan nilai aktual. Nilai MSE yang lebih kecil menunjukkan bahwa model memiliki error yang lebih rendah.\n",
        "\n",
        "**Rumus MSE:**\n",
        "$$\n",
        "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "**Interpretasi:**  \n",
        "- Nilai **MSE = 0.0035** menunjukkan bahwa rata-rata kuadrat selisih antara nilai aktual dan prediksi sangat kecil, yang berarti model cukup akurat.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Root Mean Squared Error (RMSE)**\n",
        "RMSE adalah akar dari **MSE**, yang memiliki satuan yang sama dengan variabel target. RMSE lebih mudah diinterpretasikan dibandingkan MSE.\n",
        "\n",
        "**Rumus RMSE:**\n",
        "$$\n",
        "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "**Interpretasi:**  \n",
        "- Nilai **RMSE = 0.0590** menunjukkan bahwa rata-rata kesalahan prediksi berada dalam kisaran **5.9%** dari skala target setelah dinormalisasi kembali ke skala aslinya.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. R-squared (\\( R^2 \\))**\n",
        "**R-squared** mengukur seberapa baik model dapat menjelaskan variabilitas dalam data. Nilainya berkisar antara **0 hingga 1**, di mana:\n",
        "- **\\( R^2 = 1 \\)** berarti model **sempurna** dalam menjelaskan data.\n",
        "- **Semakin mendekati 1**, semakin baik model dalam menjelaskan hubungan antara fitur dan target.\n",
        "\n",
        "**Rumus R-squared:**\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
        "$$\n",
        "di mana:\n",
        "$$\n",
        "\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i\n",
        "$$\n",
        "adalah rata-rata dari nilai aktual.\n",
        "\n",
        "**Interpretasi:**  \n",
        "- Nilai **\\( R^2 = 0.9968 \\)** berarti model dapat menjelaskan **99.68%** variabilitas dalam data, yang menunjukkan performa yang **sangat baik**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Kesimpulan**\n",
        "Dari hasil evaluasi di atas:\n",
        "- **MSE dan RMSE bernilai kecil**, menunjukkan bahwa model membuat prediksi dengan error yang sangat rendah.\n",
        "- **R-squared mendekati 1**, menunjukkan bahwa model sangat baik dalam menjelaskan data.\n",
        "\n",
        "Secara keseluruhan, model yang telah dibuat memiliki **akurasi yang tinggi dan performa yang sangat baik dalam memprediksi harga barang bekas.** 🚀"
      ],
      "metadata": {
        "id": "i2bztMak3vm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow**"
      ],
      "metadata": {
        "id": "ZqxjaY2Jw2Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MAxZfnX_ukCb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset\n",
        "data = pd.read_csv('sample_data/secondhanddataset.csv')"
      ],
      "metadata": {
        "id": "5GQR35ct1nlm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menangani nilai yang hilang (missing values)\n",
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "K51bMi9j1pNA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur (X) dan variabel target (y)\n",
        "X = data.drop(columns=['current price']).values\n",
        "y = data['current price'].values.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "l_tCoIIl1tTQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standarisasi fitur (X)\n",
        "scaler_X = StandardScaler()\n",
        "X = scaler_X.fit_transform(X)"
      ],
      "metadata": {
        "id": "JqIHxCC01t6T"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standarisasi variabel target (y)\n",
        "scaler_y = StandardScaler()\n",
        "y = scaler_y.fit_transform(y).flatten()"
      ],
      "metadata": {
        "id": "95T1sv7d1xia"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi data menjadi data latih (train) dan data uji (test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GQrpCUTy1zXV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan model MLP yang lebih baik\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation=tf.keras.layers.LeakyReLU(), input_shape=(X_train.shape[1],)),  # Lapisan pertama dengan 256 neuron\n",
        "    tf.keras.layers.Dense(128, activation=tf.keras.layers.LeakyReLU()),  # Lapisan kedua dengan 128 neuron\n",
        "    tf.keras.layers.Dense(64, activation=tf.keras.layers.LeakyReLU()),  # Lapisan ketiga dengan 64 neuron\n",
        "    tf.keras.layers.Dropout(0.3),  # Menggunakan dropout untuk mengurangi overfitting\n",
        "    tf.keras.layers.Dense(32, activation=tf.keras.layers.LeakyReLU()),  # Lapisan keempat dengan 32 neuron\n",
        "    tf.keras.layers.Dense(1)  # Lapisan output dengan 1 neuron (karena ini adalah tugas regresi)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg7AG1Ej10cx",
        "outputId": "d432354e-e196-4073-de8b-20ff1ccdf461"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengompilasi model dengan tingkat pembelajaran (learning rate) yang dioptimalkan\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])"
      ],
      "metadata": {
        "id": "ZPZq4CcO14DD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan Early Stopping untuk menghentikan pelatihan jika model tidak mengalami peningkatan\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "RuThQ4-Z16It"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=200,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXikvFQz17NG",
        "outputId": "054c4497-70e4-474b-add9-37cf731a87b9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.4646 - mae: 0.5301 - val_loss: 0.0494 - val_mae: 0.1787\n",
            "Epoch 2/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0647 - mae: 0.1947 - val_loss: 0.0180 - val_mae: 0.1079\n",
            "Epoch 3/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0304 - mae: 0.1393 - val_loss: 0.0100 - val_mae: 0.0809\n",
            "Epoch 4/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0238 - mae: 0.1175 - val_loss: 0.0126 - val_mae: 0.0916\n",
            "Epoch 5/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0245 - mae: 0.1185 - val_loss: 0.0065 - val_mae: 0.0655\n",
            "Epoch 6/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0216 - mae: 0.1117 - val_loss: 0.0082 - val_mae: 0.0715\n",
            "Epoch 7/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0191 - mae: 0.1034 - val_loss: 0.0046 - val_mae: 0.0538\n",
            "Epoch 8/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0192 - mae: 0.1066 - val_loss: 0.0070 - val_mae: 0.0681\n",
            "Epoch 9/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0192 - mae: 0.1045 - val_loss: 0.0043 - val_mae: 0.0527\n",
            "Epoch 10/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0152 - mae: 0.0910 - val_loss: 0.0058 - val_mae: 0.0609\n",
            "Epoch 11/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0141 - mae: 0.0892 - val_loss: 0.0057 - val_mae: 0.0592\n",
            "Epoch 12/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0139 - mae: 0.0878 - val_loss: 0.0069 - val_mae: 0.0673\n",
            "Epoch 13/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0132 - mae: 0.0867 - val_loss: 0.0057 - val_mae: 0.0601\n",
            "Epoch 14/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0128 - mae: 0.0868 - val_loss: 0.0077 - val_mae: 0.0715\n",
            "Epoch 15/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0847 - val_loss: 0.0067 - val_mae: 0.0649\n",
            "Epoch 16/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0137 - mae: 0.0883 - val_loss: 0.0056 - val_mae: 0.0595\n",
            "Epoch 17/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0144 - mae: 0.0896 - val_loss: 0.0038 - val_mae: 0.0490\n",
            "Epoch 18/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0126 - mae: 0.0851 - val_loss: 0.0107 - val_mae: 0.0826\n",
            "Epoch 19/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0101 - mae: 0.0738 - val_loss: 0.0129 - val_mae: 0.0911\n",
            "Epoch 20/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0115 - mae: 0.0827 - val_loss: 0.0045 - val_mae: 0.0541\n",
            "Epoch 21/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0094 - mae: 0.0715 - val_loss: 0.0065 - val_mae: 0.0662\n",
            "Epoch 22/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0102 - mae: 0.0779 - val_loss: 0.0064 - val_mae: 0.0650\n",
            "Epoch 23/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0115 - mae: 0.0807 - val_loss: 0.0067 - val_mae: 0.0656\n",
            "Epoch 24/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0112 - mae: 0.0804 - val_loss: 0.0117 - val_mae: 0.0872\n",
            "Epoch 25/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.0685 - val_loss: 0.0141 - val_mae: 0.0945\n",
            "Epoch 26/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0088 - mae: 0.0702 - val_loss: 0.0037 - val_mae: 0.0482\n",
            "Epoch 27/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0132 - mae: 0.0843 - val_loss: 0.0059 - val_mae: 0.0623\n",
            "Epoch 28/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0103 - mae: 0.0770 - val_loss: 0.0082 - val_mae: 0.0728\n",
            "Epoch 29/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0105 - mae: 0.0773 - val_loss: 0.0089 - val_mae: 0.0770\n",
            "Epoch 30/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0084 - mae: 0.0702 - val_loss: 0.0111 - val_mae: 0.0838\n",
            "Epoch 31/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0100 - mae: 0.0755 - val_loss: 0.0123 - val_mae: 0.0887\n",
            "Epoch 32/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0079 - mae: 0.0643 - val_loss: 0.0106 - val_mae: 0.0829\n",
            "Epoch 33/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0092 - mae: 0.0699 - val_loss: 0.0085 - val_mae: 0.0732\n",
            "Epoch 34/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0079 - mae: 0.0676 - val_loss: 0.0062 - val_mae: 0.0630\n",
            "Epoch 35/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0085 - mae: 0.0680 - val_loss: 0.0074 - val_mae: 0.0695\n",
            "Epoch 36/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.0699 - val_loss: 0.0244 - val_mae: 0.1239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi model dengan data uji\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PHfuPfA19ZU",
        "outputId": "a1f7dcef-fa79-42c6-c288-766cc142ce91"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d791673c680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengonversi prediksi kembali ke skala aslinya\n",
        "y_pred_original = scaler_y.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
        "y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()"
      ],
      "metadata": {
        "id": "e1_2XoVJ2B82"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung metrik evaluasi model\n",
        "mse = tf.keras.losses.MeanSquaredError()(y_test_original, y_pred_original).numpy()  # Mean Squared Error (MSE)\n",
        "rmse = np.sqrt(mse)  # Root Mean Squared Error (RMSE)\n",
        "mae = tf.keras.losses.MeanAbsoluteError()(y_test_original, y_pred_original).numpy()  # Mean Absolute Error (MAE)"
      ],
      "metadata": {
        "id": "rxdXiLe02EeD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung koefisien determinasi (R-squared)\n",
        "y_mean = y_test_original.mean()\n",
        "ss_total = ((y_test_original - y_mean) ** 2).sum()  # Total sum of squares (variabilitas total)\n",
        "ss_res = ((y_test_original - y_pred_original) ** 2).sum()  # Residual sum of squares (variabilitas yang tidak dijelaskan)\n",
        "r_squared = 1 - (ss_res / ss_total)  # Perhitungan R²"
      ],
      "metadata": {
        "id": "2Ep-AxYb2HRS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan hasil evaluasi model\n",
        "print(f'MSE: {mse:.4f}')\n",
        "print(f'RMSE: {rmse:.4f}')\n",
        "print(f'MAE: {mae:.4f}')\n",
        "print(f'R-squared: {r_squared:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i0Sq1rE2IwW",
        "outputId": "505a215b-aed1-42d5-fe16-c1b1196a00ed"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 59534604.0000\n",
            "RMSE: 7715.8672\n",
            "MAE: 6072.8125\n",
            "R-squared: 0.9965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluasi Model: MSE, RMSE, dan R-squared**\n",
        "\n",
        "Setelah melatih model, kita mengevaluasi performanya menggunakan tiga metrik utama:\n",
        "\n",
        "1. **Mean Squared Error (MSE)**\n",
        "2. **Root Mean Squared Error (RMSE)**\n",
        "3. **R-squared (\\( R^2 \\))**\n",
        "\n",
        "Hasil evaluasi yang diperoleh:"
      ],
      "metadata": {
        "id": "paC82ZP538mX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **1. Mean Squared Error (MSE)**\n",
        "MSE mengukur rata-rata kesalahan kuadrat antara nilai prediksi dan nilai aktual. Nilai MSE yang lebih kecil menunjukkan bahwa model memiliki error yang lebih rendah.\n",
        "\n",
        "**Rumus MSE:**\n",
        "$$\n",
        "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "**Interpretasi:**  \n",
        "- Nilai **MSE = 59,534,604.0000** menunjukkan bahwa rata-rata kuadrat selisih antara nilai aktual dan prediksi cukup besar, yang berarti terdapat beberapa kesalahan dalam prediksi model.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Root Mean Squared Error (RMSE)**\n",
        "RMSE adalah akar dari **MSE**, yang memiliki satuan yang sama dengan variabel target. RMSE lebih mudah diinterpretasikan dibandingkan MSE.\n",
        "\n",
        "**Rumus RMSE:**\n",
        "$$\n",
        "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "**Interpretasi:**  \n",
        "- Nilai **RMSE = 7,715.8672** menunjukkan bahwa rata-rata kesalahan prediksi berada dalam kisaran **7,715 unit dari skala target**, yang bisa menjadi indikasi bahwa model masih memiliki error yang cukup besar dalam skala aslinya.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Mean Absolute Error (MAE)**\n",
        "MAE mengukur rata-rata selisih absolut antara nilai aktual dan nilai prediksi, memberikan gambaran tentang seberapa besar kesalahan rata-rata model.\n",
        "\n",
        "**Rumus MAE:**\n",
        "$$\n",
        "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
        "$$\n",
        "\n",
        "**Interpretasi:**  \n",
        "- Nilai **MAE = 6,072.8125** menunjukkan bahwa secara rata-rata, prediksi model meleset sekitar **6,072 unit** dari nilai sebenarnya.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. R-squared (\\( R^2 \\))**\n",
        "**R-squared** mengukur seberapa baik model dapat menjelaskan variabilitas dalam data. Nilainya berkisar antara **0 hingga 1**, di mana:\n",
        "- **\\( R^2 = 1 \\)** berarti model **sempurna** dalam menjelaskan data.\n",
        "- **Semakin mendekati 1**, semakin baik model dalam menjelaskan hubungan antara fitur dan target.\n",
        "\n",
        "**Rumus R-squared:**\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
        "$$\n",
        "di mana:\n",
        "$$\n",
        "\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i\n",
        "$$\n",
        "adalah rata-rata dari nilai aktual.\n",
        "\n",
        "**Interpretasi:**  \n",
        "- Nilai **\\( R^2 = 0.9965 \\)** berarti model dapat menjelaskan **99.65%** variabilitas dalam data, yang menunjukkan performa yang **sangat baik** dalam menangkap pola data.\n",
        "\n",
        "---\n",
        "\n",
        "## **Kesimpulan**\n",
        "Dari hasil evaluasi di atas:\n",
        "- **MSE dan RMSE bernilai cukup besar**, menunjukkan bahwa model masih memiliki error dalam prediksi.\n",
        "- **MAE juga cukup besar**, mengindikasikan selisih absolut antara nilai aktual dan prediksi masih cukup tinggi.\n",
        "- **R-squared mendekati 1**, menunjukkan bahwa model sangat baik dalam menjelaskan data meskipun masih ada error yang perlu diperbaiki.\n",
        "\n",
        "Secara keseluruhan, model memiliki **kemampuan yang sangat baik dalam menjelaskan variabilitas data**, tetapi masih terdapat kesalahan prediksi yang cukup besar, sehingga perlu dilakukan analisis lebih lanjut untuk meningkatkan akurasi model. 🚀\n"
      ],
      "metadata": {
        "id": "Mx80vy9h3L_6"
      }
    }
  ]
}